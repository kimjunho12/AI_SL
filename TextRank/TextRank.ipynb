{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load library"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "# SentenceTokenizer Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\"\n",
    "        ,\"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\",'로써',\n",
    "        '해당', '니다']\n",
    "    def url2sentences(self, url):                   # URL일 경우 Text 추출\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)   # 텍스트에서 문장별로 반환\n",
    "        print(article.text)\n",
    "        print('*'*120)\n",
    "\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "            return sentences\n",
    "\n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "              nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence))\n",
    "            if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n"
   ]
  },
  {
   "source": [
    "# GrapMatrix Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "        \n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "source": [
    "# Rank Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "source": [
    "# TextRank Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenize.url2sentences(text)\n",
    "        else:\n",
    "            self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "\n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def keywords(self, word_num=15):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        return keywords\n"
   ]
  },
  {
   "source": [
    "# Main"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "안녕하세요 쏘선생님입니다.\n",
      "\n",
      "대학교를 목표로 하시는군요, 애견학과가 있는 학교로는\n",
      "\n",
      "대표적으로 원광대, 신구대, 연희대 등이있습니다.\n",
      "\n",
      "애견과인만큼, 이론이나 실무를 공부하겠죠.\n",
      "\n",
      "만약 취업을 목적으로 하시는거라면, 저는 대학교는 추천드리지 않습니다.\n",
      "\n",
      "애견분야는 학력이 아닌, 실력과 자격증으로 손님들이 오시는거고,\n",
      "\n",
      "해당 취업기관도 실무능력을 더 우선시합니다.\n",
      "\n",
      "애견학과에 나왔다고 우대를 하는게 아닌, 실력중심으로 우대를 하기에,\n",
      "\n",
      "실력이 있어야 취득할 수 있는 자격증을 더 봅니다.\n",
      "\n",
      "애견분야도 여러 분야가 있습니다. 정확히 어느 분야로 취업을 원하시나요?\n",
      "\n",
      "만약 취업을 원하시는거라면, 저는 자격증을 추천드립니다.\n",
      "\n",
      "저는 반려동물관리사 선생님입니다.\n",
      "\n",
      "애견과 관련된 자격증을 취득하고싶거나, 더 자세히 알고싶으시다면\n",
      "\n",
      "질문해주세요. 정확하게 답변해드리겠습니다.\n",
      "\n",
      "자신이 원하는 분야와, 목표를 세우고 자격증을 준비하세요.\n",
      "\n",
      "유능한 선생님과 상담해보세요.\n",
      "\n",
      "문의주시면 반려동물관리사 직업 자료와 핵심기출문제 보내드립니다^^\n",
      "\n",
      "(상담문의)\n",
      "\n",
      "http://naver.me/I5jden8H\n",
      "\n",
      "핸드폰으로 문자나 카톡 남겨주셔도 됩니다\n",
      "************************************************************************************************************************\n",
      "['자격증', '애견', '취업', '실무', '능력', '손님', '우선', '기관', '시합', '학력', '오시', '문의', '실력', '문제', '자료']\n",
      "만약 취업을 목적으로 하시는 거라면, 저는 대학교는 추천 드리지 않습니다.\n",
      "\n",
      "우대를 하는 게 아닌, 실력 중심으로 우대를 하기에, 실력이 있어야 취득할 수 있는 자격증을 더 봅니다.\n",
      "\n",
      "애견분야도 여러 분야가 있습니다.\n",
      "\n",
      "정확히 어느 분야로 취업을 원하시나요?\n",
      "\n",
      "만약 취업을 원하시는 거라면, 저는 자격증을 추천 드립니다.\n",
      "\n",
      "keywords : ['자격증', '애견', '취업', '실무', '능력', '손님', '우선', '기관', '시합', '오시', '학력', '문의', '실력', '자료', '직업']\n"
     ]
    }
   ],
   "source": [
    "url = input()\n",
    "textrank = TextRank(url)\n",
    "print(textrank.keywords())\n",
    "for row in textrank.summarize(5):\n",
    "    print(row)\n",
    "    print()\n",
    "print('keywords :',textrank.keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['자격증',\n",
       " '애견',\n",
       " '취업',\n",
       " '실무',\n",
       " '능력',\n",
       " '손님',\n",
       " '우선',\n",
       " '기관',\n",
       " '시합',\n",
       " '오시',\n",
       " '학력',\n",
       " '문의',\n",
       " '실력',\n",
       " '문제',\n",
       " '자료']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "textrank.keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "자격증 : 5\n애견 : 6\n취업 : 4\n실무 : 2\n능력 : 1\n손님 : 1\n우선 : 1\n기관 : 1\n시합 : 1\n학력 : 1\n오시 : 1\n문의 : 2\n실력 : 3\n문제 : 1\n자료 : 1\n"
     ]
    }
   ],
   "source": [
    "for i in textrank.keywords():\n",
    "    print(i + ' : ' + str(raw.count(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}