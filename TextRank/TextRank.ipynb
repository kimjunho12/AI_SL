{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load library"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "# SentenceTokenizer Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\"\n",
    "        ,\"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\",'로써',\n",
    "        '해당', '합니다']\n",
    "    def url2sentences(self, url):                   # URL일 경우 Text 추출\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)   # 텍스트에서 문장별로 반환\n",
    "        print(article.text)\n",
    "        print('*'*120)\n",
    "\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "            return sentences\n",
    "\n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "              nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence))\n",
    "            if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n"
   ]
  },
  {
   "source": [
    "# GrapMatrix Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "        \n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "source": [
    "# Rank Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "source": [
    "# TextRank Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenize.url2sentences(text)\n",
    "        else:\n",
    "            self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "\n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        return keywords\n"
   ]
  },
  {
   "source": [
    "# Main"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "안녕하세요.\n",
      "\n",
      "교육상담 전문 학습플래너 김유진입니다.\n",
      "\n",
      "​\n",
      "\n",
      "동물보건사 자격증이 개설되면서 동물병원에서 근무할 때에\n",
      "\n",
      "꼭 필요한 요소로 적용될 예정이며, 그로 인해 수의테크니션을\n",
      "\n",
      "희망하거나 애완동물 관련 사업쪽으로 취업하려는 분들께서\n",
      "\n",
      "동물보건사 자격증에 대해서 많이들 알아보고계십니다.\n",
      "\n",
      "​\n",
      "\n",
      "동물보건 관련 전공으로 최소 전문대학교 이상의 학력을 소지하거나\n",
      "\n",
      "실무경력이 있어야지만 국가고시를 응시할 수 있습니다.\n",
      "\n",
      "2021년부터 수의사법이 개정되고 국가자격으로 시행되면서\n",
      "\n",
      "무조건 자격이 있어야지만 수의테크니션으로 근무를 할 수 있다고 합니다.\n",
      "\n",
      "​\n",
      "\n",
      "학점은행제에는 애완동물관리전공 전문학사학위 과정이\n",
      "\n",
      "개설되어있으며, 민간자격증이 아닌 확실한 학력을 취득할 수 있으며\n",
      "\n",
      "수의테크니션 자격을 갖추실 수 있습니다. 무엇보다 수능성적도 필요없고\n",
      "\n",
      "고등학교 졸업 이상의 학력만 있다면 학점은행제를 이용하실 수 있습니다.\n",
      "\n",
      "​\n",
      "\n",
      "고졸학력으로 전문학사학위를 취득하려면\n",
      "\n",
      "총 80학점을 이수하셔야하고, 애완동물관리전공 전문학사를\n",
      "\n",
      "취득하시려면 전공 45학점 + 교양 15학점을 필수로\n",
      "\n",
      "충족하고 총 80학점을 이수하셔야 합니다.\n",
      "\n",
      "전공 45학점 중에서도 전공필수 18학점을 이수하셔야\n",
      "\n",
      "안정적으로 전문학사학위 취득이 가능합니다.\n",
      "\n",
      "​\n",
      "\n",
      "문제는 온라인강의로 모든 전공학점을 채우는 것이 쉽지 않아서\n",
      "\n",
      "대체수단으로 자격증을 취득하셔야해서, 애완동물관리전공을\n",
      "\n",
      "진행하는 학생들은 전공자격증인 \"축산산업기사\"자격증을 병행합니다.\n",
      "\n",
      "축산산업기사는 학점은행제로 41학점을 보유하고있으면 시험 응시가 가능합니다.\n",
      "\n",
      "축산산업기사 자격증 취득 시 전공필수학점으로 인정됩니다.\n",
      "\n",
      "​\n",
      "\n",
      "학점은행제는 일반대학과 다르게\n",
      "\n",
      "학년제가 아닌 학점제로 진행되어서 일정학점을\n",
      "\n",
      "취득하면 학위를 수여받을 수 있어서 학점대체 가능한\n",
      "\n",
      "자격증,독학사,전적대학점을 활용해서 학습기간을 단축하여\n",
      "\n",
      "단기간에 학위취득이 가능합니다.\n",
      "\n",
      "​\n",
      "\n",
      "애완동물관리 전공 전문학사학위 취득하면 동물보건사\n",
      "\n",
      "자격조건이 갖추어지고, 학점은행제 온라인 과정으로\n",
      "\n",
      "수의테크니션 자격증 응시자격 조건을 갖출 수 있습니다.\n",
      "\n",
      "​\n",
      "\n",
      "아래 네임카드를 통한 문의주시면, 학점은행제를 통해\n",
      "\n",
      "동물보건사 자격증/수의테크니션 자격증 응시자격 갖추실 수 있도록\n",
      "\n",
      "애완동물관리전공 전문학사학위 취득 전과정 책임지고 도움드리겠습니다.\n",
      "\n",
      "항시 무료상담 가능하며, 지금도 상담 가능합니다. 감사합니다 :)\n",
      "************************************************************************************************************************\n",
      "합니다.\n",
      "\n",
      "무엇보다 수능성적도 필요없고 고등학교 졸업 이상의 학력만 있다면 학점은행제를 이용하실 수 있습니다.\n",
      "\n",
      "​ 고졸 학력으로 전문학 사학위를 취득하려면 총 80 학점을 이수하셔야 하고, 애완동물관리 전공 전문학 사를 취득하시려면 전공 45 학점 + 교양 15 학점을 필수로 충족하고 총 80 학점을 이수하셔야 합니다.\n",
      "\n",
      "​ 학점은행제는 일반대학과 다르게 학년제가 아닌 학점제로 진행되어서 일정 학점을 취득하면 학위를 수여 받을 수 있어서 학점 대체 가능한 자격증, 독 학사, 전적대학점을 활용해서 학습기간을 단축하여 단기간에 학위 취득이 가능합니다.\n",
      "\n",
      "​ 애완동물관리 전공 전문학 사학위 취득하면 동물 보건 사 자격조건이 갖추어 지고, 학점은행제 온라인 과정으로 수의 테크니 션 자격증 응시자격 조건을 갖출 수 있습니다.\n",
      "\n",
      "keywords : ['자격증', '취득', '애완동물', '전공', '학점은행제', '학위', '보건', '동물', '테크', '관리']\n"
     ]
    }
   ],
   "source": [
    "url = input()\n",
    "textrank = TextRank(url)\n",
    "for row in textrank.summarize(5):\n",
    "    print(row)\n",
    "    print()\n",
    "print('keywords :',textrank.keywords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}